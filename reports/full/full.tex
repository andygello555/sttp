\documentclass[]{full}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{array}
\usepackage{minted}
\usepackage{cprotect}
\usepackage{caption}
\usepackage{import}
\usepackage[style=ieee]{biblatex}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tcolorbox}
\usepackage{etoolbox}
\usepackage{mathtools}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[subsubsection]
\addbibresource{ref.bib}

% \BeforeBeginEnvironment{minted}{\begin{tcolorbox}}%
% \AfterEndEnvironment{minted}{\end{tcolorbox}}%

%%%%%%%%%%%%%%%%%%%%%%
%%% Input project details
\def\studentname{Jakab Zeller}
\def\reportyear{2022}
\def\projecttitle{Computer Language Design and Engineering}
\def\supervisorname{Adrian Johnstone}
\def\degree{BSc (Hons) in Computer Science}
\def\fullOrHalfUnit{Full Unit} % indicate if you are doing the project as a Full Unit or Half Unit
\def\finalOrInterim{Interim} % indicate if this document is your Final Report or Interim Report

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%
%%% Declaration

\chapter*{Declaration}

This report has been prepared on the basis of my own work. Where other published and unpublished source materials have been used, these have been acknowledged.

\vskip3em

Word Count:

\vskip3em

Student Name: \studentname

\vskip3em

Date of Submission: 2022

\vskip3em

Signature: \includegraphics[height=4em]{assets/signature.jpeg}

\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Table of Contents
\tableofcontents\pdfbookmark[0]{Table of Contents}{toc}\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Your Abstract here

\begin{abstract}

Although there exists many tools for testing and developing web-based APIs, there are not many solutions which provide full user freedom when it comes to control-flow. This project proposes a solution in the form of a dynamically typed, interpreted, scripting language with features enabling the use of web-based APIs `out-of-the-box', as well as other helpful tooling.

\end{abstract}
\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Introduction
\chapter{Motivations}
\label{chap:motivations}

\begin{definition}[Web API]
    A web API is an application programming interface that is hosted on a web server accessible via the HTTP protocol. Endpoints within a web API specify where an action or resource lies, creating a \textbf{directory like structure} of `methods'.
\end{definition}

Web APIs are in the background of most applications and services we use. Everything from requesting the weather in a certain country, accessing up to date exchange rate information, accessing personal calendar information. Can all be achieved through the use of specific web APIs. The number of web APIs has risen substantially over the last decade and a half. \href{https://www.programmableweb.com/category/all/apis}{ProgrammableWeb}, cites over 24,000 APIs (as of January 2022). A large increase from 2013: 9000, and an even larger increase from 2005: 105\textsuperscript{\cite{duvander_2013}}.

\begin{definition}[Web Scraping]
    Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites\textsuperscript{\cite{web_scraping_wikipedia_2022}}.
\end{definition}

Partly due to the ubiquity of web APIs, as well as my interest toward creating autonomous web-scraping solutions. I have gained a lot of experience using them, and have even developed a few of my own. Before beginning this project, I had been working on a large library of web scraping procedures, to track, scrape, and store information on several hundreds applications on the popular PC video game e-tailer: \href{https://store.steampowered.com/}{Steam}. This was largely achieved by using Steam's Web API, but also by scraping data from webpages, dashboards, and portals. The data retrieved by said procedures would be stored in a database, accessible via a web API. Most of the endpoints within this API perform various complex manipulations and aggregates to return a representation of the data that is easier to handle for users. This interest soon stemmed into my professional life, when I was asked to implement this system on a larger scale for a indie video game publisher. Thus increasing the workload and data throughput of the server.

Soon, the complexity of the codebase spiralled out of control. The test suites that were written to check if the procedures were functioning properly, became large and unruly. Frequent and undocumented changes to the Steam Web API, would render some procedures out of action for several days. To deal with this issue, I moved the implementation of some of the test suites to Insomnia (a REST client that allows you to build test suites for web APIs). Whilst having an extensive feature-set for a REST client, Insomnia lacked control-flow constructs for complex request and response handling. Constructs such as conditionals, looping, and error handling, are missing/very hard to implement. Soon after, the tests written in Insomnia were abandoned in favour of refactored versions of the previous tests within the code base itself.

Due to this need of greater functionality, I propose a scripting language purposefully designed as a HTTP client and test suite first.

\begin{center}
\verb|sttp| \textit{(amalgamation of `scripting' and `HTTP')}
\end{center}

\verb|sttp| was made in order to test web APIs that have complex interaction flows, or APIs that are just black boxes. The main features that \verb|sttp| was designed in mind with are:

\begin{enumerate}
    \item \textbf{Builtin HTTP client}. There must be a way to make HTTP requests.
    \item \textbf{Concise, quick and manageable builtin testing}. Tests should be able to be easily implemented and modifiable. There should also be a way of grouping tests for actions that access a similar resource. Just like how REST APIs are designed.
    \item \textbf{JSON values and JSONPath}. All values in \verb|sttp| can be parsed to JSON and back. As most web APIs default to JSON as their interchange format, it made sense to treat all data as JSON. \textbf{JSONPath}, is a syntax for accessing JSON values in the similar vain of XPath for XML\textsuperscript{\cite{goessner_2007}}.
    \item \textbf{Executing HTTP requests concurrently}. Concurrency should be easy and encouraged.
    \item \textbf{Command line usage}. I regularly tinker and test endpoints on the command line. Thus I expect \verb|sttp| should be able to be run from the command line. This means creating a whitespace independent grammar that allows for input to be typed on a single line.
    \item \textbf{Web scraping functionality}. Such as a HTML parser, tree search functions, and filtering.
\end{enumerate}

To achieve this, I decided to write an interpreter using Go\textsuperscript{\cite{the_go_programming_language}} and the participle parser generator\textsuperscript{\cite{thomas_2021}}. I chose Go as its accompanying toolset allows for quick testing and benchmarking. I knew this would be useful when developing the language and benchmarking the concurrency constructs within the language. This native tooling also allows for rapid development and less external dependencies. At the beginning of the project I was comfortable at writing code in Go, as I had used it for numerous other projects in the past.

I chose the participle parser generator, as it was (and still is) being actively developed, and had a plethora of examples available. It also has an interesting way of defining the accepted grammar for the generated parser. Encoding EBNF within the AST type declarations, the instantiated versions of which will be returned by the generated parser (explained further in PLACEHOLDER). However, the generated parsers are recursive descent parsers. This meant I had to design my language without any left-recursion. Thankfully, the iteration operator in participle's EBNF notation, solved some of the issues, such as left-associative operators.

\section{The Future}

As explained in the \hyperref[chap:motivations]{motivations introduction}, much of my professional life and pastimes involve creating and testing web APIs. Therefore, \verb|sttp| is something that I would hope to use in both domains. I plan on continuing development on \verb|sttp| in the background to add newer features that will solve issues that occur frequently in my work life. Go is also rising in popularity within the web API space, and now that I am fairly fluent in it, I hope to use it within the workplace soon.

As I enjoyed learning the theory behind programming language design and engineering as much as I enjoyed creating \verb|sttp|. I hope I can make better use of this knowledge in the appropriate field of work. I have found the material covered within \textit{CS3480: Software Language Engineering}, quite eye-opening as to the number of different Domain Specific Languages (DSL), in use and in development. There is a DSL for everything from CAD 3D modelling to programming robots\textsuperscript{\cite{nordmann_hochgeschwender_wrede_2014}}. A job within this area could have work that I find rewarding and interesting.

\chapter{Development}
\label{chap:development}

Before development began I wrote a few test programs to get back up to speed with programming in Go, as well as familiarising myself with participle.

\import{sections}{2-1-four-func-calc.tex}

\import{sections}{2-2-regex-minimiser.tex}

\import{sections}{2-3-grammar-ast.tex}

\import{sections}{2-4-data-structures.tex}

\import{sections}{2-5-casting.tex}

\import{sections}{2-6-operators.tex}

\section{Evaluating AST nodes}

\begin{figure}[H]
    \begin{center}
        \textbf{Diary Entry}\\[0.5em]
        \textit{``Made final touches to interim report before handing in. Completed all operator actions as well as defining agnostic evaluation methods for all precedence levels. I also implemented assignment statements as well as if-elif-else statements. Along with JSONPath setting and getting. I had to rewrite my Heap data structure and my Value structure."}\\[0.5em]
        \tiny{11:51 am on December 6, 2021}
    \end{center}
\end{figure}
    
Each AST node within \verb|sttp| implements the \verb|evalNode| interface. This defines the \mintinline[breaklines]{go}{Eval(vm VM) (err error, result *data.Value)} instance method (among other things), that will be called on the root AST node (\verb|Program|) with a fresh \verb|VM| instance. The \verb|Eval| instance method of each lower AST node will be called, passing this \verb|VM| instance to each. The \verb|err| return parameter is used to `bubble' up an error/exception if one occurs in any of the AST nodes. This error will either float up to the \verb|Program| root, or to a \verb|TryCatch| AST node. The \verb|evalNode| interface was mainly implemented to improve readability and reduce complexity with the evaluation of AST nodes within \hyperref[sec:development-ast-nodes-expressions]{expression subtrees}.

\import{sections}{2-7-1-jsonpath-assignment.tex}

\import{sections}{2-7-2-expressions.tex}

\import{sections}{2-7-3-if-elif-else.tex}

\import{sections}{2-7-4-iterations.tex}

\import{sections}{2-7-5-functions.tex}

\import{sections}{2-7-6-http-methods.tex}

\import{sections}{2-7-7-testing.tex}

\import{sections}{2-7-8-try-catch-throw.tex}

\import{sections}{2-7-9-batch-statement.tex}

\import{sections}{2-7-10-builtins.tex}

\chapter{Evaluation}
\label{chap:evaluation}

Overall, I am quite pleased with what I accomplished in the given amount of time. If I had planned anymore features, or changed any of the technologies that I had used, I think I would have been struggling to finish the project in time.

\section{What went well}

The project continued at a steady pace with no real hitches that affected the overall running of the project.

I had some apprehensions of the performance of the \verb|batch| statement implementation. However, I knew that using Go to implement the interpreter would give the best shot at acquiring the required threaded performance.

\verb|sttp| proved to be useful during the rewrite of the tests that were mentioned in the \hyperref[chap:motivations]{motivations}. The tests that check if the scraping targets have changed on the sources that I scrape from are stored within a single directory. This directory is then executed as a \verb|TestSuite| daily. If there are unforeseen changes the \verb|TestSuite| will fail to indicate this, and then the appropriate changes can be made to the scrape procedures.

\section{Things that I would change}

In the future I would like to create a frontend for a compiler that translates \verb|sttp| code into an intermediary format, such as Java bytecode or WASM, that can then have native code generated from it. Or, maybe a transpiler that compiles to another programming language such as Go or C. This isn't because the performance of the \verb|sttp| interpreter is unsatisfactory, I am just interested in creating a compiler for \verb|sttp|.

\verb|sttp| uses operators to perform actions that would usually be assigned to a builtin function. Even though I think this methodology is quite interesting, it might lead to alienation amongst new users. Therefore, I think introducing builtin functions for these actions is more suitable. I would also make a few changes to the grammar of \verb|sttp|:

\begin{itemize}
    \item More assignment operators such as \verb|+=| and \verb|-=|.
    \item Remove semi-colons from the end of statements ending with \verb|end|. Even though this makes sense grammatically and from a completeness standpoint, it is ultimately unnecessary.
    \item Use of \verb|MethodCall|s and \verb|FunctionCall|s as the root property of JSONPath expressions. This is so that the results of these don't first need to be stored within a variable to be accessed via JSONPath.
    \item Making most of the tokens matched by the lexer smaller, so that less typing needs to be done by the programmer and it is easier to fit onto a terminal screen.
    \item Not a grammatical change, but lazy operation of logical operators would reduce the overhead of long logical expressions.
\end{itemize}

Most of these decisions come after realising that the grammar of the language makes it too `verbose', and there is a lot of time spent writing keywords and tokens.

Another thing I would change is the algorithm used to compute the \verb|batch| statement. Since the implementation I have thought of several better, and more efficient ways of executing it. One of them involves starting the worker goroutines alongside the interpreter in the first pass. Whenever the interpreter steps into a \verb|MethodCall| AST node, it will enqueue it as a job instantly. This job will then be executed by a worker thread and then added to the result queue. The second pass would be unchanged from the original algorithm. This method leverages the speed increase from executing the HTTP requests in parallel, but is also doing the analysis pass (first pass) at the same time.

Most programming languages such as Java and Go, allow you to generate formal documentation for the source code from the documentation and comments imbedded within it. This is something that I would like to add to \verb|sttp|, but instead of documenting the implementation of the source code itself, the programmer would document the API. Such as the actions and resources available for the API, and the parameters accepted by each. This documentation could then generate a set of webpages that would serve as documentation for the API itself.

\chapter{Discussion on recursive descent parser generators}
\label{chap:discussion}

\verb|sttp| scripts are parsed using a recursive descent parser generated by the participle parser generator. Therefore, the grammar of \verb|sttp| is right-recursive, as opposed to left-recursive. A grammar is left-recursive if it has a non-terminal $A$ such that there is a derivation sequence $A \stackrel{\mathclap{\normalfont\mbox{+}}}{\Rightarrow} A \alpha$ for some string $\alpha$. Left recursion causes recursive descent to fall into an infinite loop due to the parse tree being constructed in a depth-first leftmost fashion\textsuperscript{\cite{scott_johnstone_1998}}.

Many recursive descent parser generators, participle included, can detect left-recursion within a grammar using a left-recursion detection algorithm. This works by checking if each production rule is \textbf{directly left-recursive}, by checking if the leftmost non-terminal on the RHS is the same as the non-terminal on the LHS. It then recursively checks each production rule of every non-terminal within that production rule for \textbf{indirect left-recursion}.

Even thought left-recursion algorithms, such as left-factoring, exist; many recursive descent parser generators, participle included, do not implement them. This might be because it is computationally expensive, or because it introduces extra production rules not in the original grammar.

Most of the grammars for modern programming languages are formally left-recursive. This is because most operations are left-associative (evaluated from left to right). Left-associative operators within grammars are left-recursive because, if the leftmost subtrees of the operations need to be evaluated first, this requires the grammar to introduce a production rule for that operator with a non-terminal on the left of the RHS.

\begin{figure}[H]
    \begin{center}
        \begin{verbatim}
                        E ::= T | E "+" T
                        T ::= F | F "**" T
                        F ::= Num | "(" E ")"
        \end{verbatim}
    \end{center}
    \vspace{-1.5em}
    \cprotect\caption{\label{fig:4.1}Here the \verb|+| operator is left-associative, and \verb|**| is right-associative. \verb|E ::= E "+" T| is left-recursive.}
\end{figure}

Fortunately, because participle uses EBNF, it means that I could encode left-associative operators within the \verb|sttp| grammar fairly easily. Using iteration instead of recursion can remove left-recursion from the grammar\textsuperscript{\cite{pattis_2021}}. This will affect the produced parse tree as now there can be multiple children for matched for a certain operator's node.

\begin{figure}[H]
    \begin{center}
        \begin{verbatim}
                        E ::= T { "+" T }
                        T ::= F [ "**" T ]
                        F ::= Num | "(" E ")"
        \end{verbatim}
    \end{center}
    \vspace{-1.5em}
    \caption{\label{fig:4.2}The grammar in \hyperref[fig:4.1]{fig. 4.1} rewritten with the EBNF to remove left recursion.}
\end{figure}

Another quirk of \verb|sttp|'s grammar is that the precedence of operators is encoded within the grammar itself using grammar rules rather than after the parse tree is produced. This was done so that the precedence levels could be easily read from the grammar specification. However, doing so might have an impact on performance. This is because recursive descent expression parsers produce parse trees proportional in complexity to the number of operators supported, which leads to high memory usage\textsuperscript{\cite{bendersky_2012}}.

If parsing time or memory usage grows too great in the future, this is something that I would want to change within \verb|sttp|. If this does happen, I would switch over to a precedence climbing algorithm\textsuperscript{\cite{chu_2017}}. This is fairly easily implementable within participle and there is even an \href{https://github.com/alecthomas/participle/blob/master/_examples/precedenceclimbing/main.go}{example for it}.

\chapter{Professional Issues}
\label{chap:professional-issues}

There are a few professional issues that exist within the area of programming language design:

\begin{enumerate}
    \item Programming language design and engineering in languages used within safety critical systems.
    \item The role programming languages play in ethical and and unethical uses for technology.
    \item Is there a right to literacy in programming, and if not should there be?
\end{enumerate}

To me, the most interesting professional issue to discuss is if there is a right to literacy in programming. The meaning of the word `literacy' has changed from word and letter recognition, which was more prominent before the 1950s, to become what is today, which is the ability to read and write\textsuperscript{\cite{gee_1991}}. Therefore, the right to literacy is the right to acquire the resources and teaching required to develop sufficient skills in reading and writing. This has been supported by the 1997 Hamburg Declaration\textsuperscript{\cite{hamburg_1997}} and is even a fundamental declaration within the European union\textsuperscript{\cite{edrl_2016}}.

Recently, many people have thought that the right to literacy should also extend to programming. This would mean that anyone who wants to learn how to program should be able to. This would mean designing languages that are easily teachable, and learnable. But what makes a programming language easy to teach and to learn? Unfortunately there is not much information available on this subject other than personal opinions. However, the programming languages that are cited the most often for being easy to learn are the following (along with some of their characteristics):

\begin{enumerate}
    \item Python: \textbf{dynamically typed}, \textbf{multiple paradigms}\textsuperscript{\cite{5_easiest_and_hardest_programming_languages_to_learn}}\textsuperscript{\cite{6_easiest_programming_languages_to_learn}}\textsuperscript{\cite{deery_2021}}
    \item JavaScript: \textbf{dynamically typed}\textsuperscript{\cite{5_easiest_and_hardest_programming_languages_to_learn}}\textsuperscript{\cite{6_easiest_programming_languages_to_learn}}\textsuperscript{\cite{deery_2021}}
    \item Ruby: \textbf{dynamically typed}\textsuperscript{\cite{6_easiest_programming_languages_to_learn}}\textsuperscript{\cite{deery_2021}}
    \item Java: \textbf{statically typed}\textsuperscript{\cite{5_easiest_and_hardest_programming_languages_to_learn}}\textsuperscript{\cite{6_easiest_programming_languages_to_learn}}
    \item C: \textbf{statically typed}\textsuperscript{\cite{5_easiest_and_hardest_programming_languages_to_learn}}\textsuperscript{\cite{6_easiest_programming_languages_to_learn}}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%
%%% sttp Specification

\appendix

\cprotect\chapter{\verb|sttp| Specification}
\label{appendix:sttp-specification}

\verb|sttp| (amalgamation of \textit{scripting} and \textit{HTTP}) is a dynamically typed, interpreted, scripting language written in Go using the participle parser generator by Alec Thomas\textsuperscript{\cite{thomas_2021}}. Below is the formal grammar definition of the language:

\import{../specification_for_language}{specification_for_language_body.tex}

%%%% ADD YOUR BIBLIOGRAPHY HERE
\newpage
\label{endpage}

\printbibliography

\end{document}

\end{article}

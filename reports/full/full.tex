\documentclass[]{full}
\usepackage{amsthm}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{array}
\usepackage{minted}
\usepackage{cprotect}
\usepackage{caption}
\usepackage{import}
\usepackage[style=ieee]{biblatex}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[subsubsection]
\addbibresource{ref.bib}

%%%%%%%%%%%%%%%%%%%%%%
%%% Input project details
\def\studentname{Jakab Zeller}
\def\reportyear{2022}
\def\projecttitle{Computer Language Design and Engineering}
\def\supervisorname{Adrian Johnstone}
\def\degree{BSc (Hons) in Computer Science}
\def\fullOrHalfUnit{Full Unit} % indicate if you are doing the project as a Full Unit or Half Unit
\def\finalOrInterim{Interim} % indicate if this document is your Final Report or Interim Report

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%
%%% Declaration

\chapter*{Declaration}

This report has been prepared on the basis of my own work. Where other published and unpublished source materials have been used, these have been acknowledged.

\vskip3em

Word Count:

\vskip3em

Student Name: \studentname

\vskip3em

Date of Submission: 2022

\vskip3em

Signature: \includegraphics[height=4em]{assets/signature.jpeg}

\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Table of Contents
\tableofcontents\pdfbookmark[0]{Table of Contents}{toc}\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Your Abstract here

\begin{abstract}

Although there exists many tools for testing and developing web-based APIs, there are not many solutions which provide full user freedom when it comes to control-flow. This project proposes a solution in the form of a dynamically typed, interpreted, scripting language with features enabling the use of web-based APIs `out-of-the-box', as well as other helpful tooling.

\end{abstract}
\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Introduction
\chapter{Motivations}
\label{chap:motivations}

\begin{definition}[Web API]
    A web API is an application programming interface that is hosted on a web server accessible via the HTTP protocol. Endpoints within a web API specify where an action or resource lies, creating a \textbf{directory like structure} of `methods'.
\end{definition}

Web APIs are in the background of most applications and services we use. Everything from requesting the weather in a certain country, accessing up to date exchange rate information, accessing personal calendar information. Can all be achieved through the use of specific web APIs. The number of web APIs has risen substantially over the last decade and a half. \href{https://www.programmableweb.com/category/all/apis}{ProgrammableWeb}, cites over 24,000 APIs (as of January 2022). A large increase from 2013: 9000, and an even larger increase from 2005: 105\textsuperscript{\cite{duvander_2013}}.

\begin{definition}[Web Scraping]
    Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites\textsuperscript{\cite{web_scraping_wikipedia_2022}}.
\end{definition}

Partly due to the ubiquity of web APIs, as well as my interest toward creating autonomous web-scraping solutions. I have gained a lot of experience using them, and have even developed a few of my own. Before beginning this project, I had been working on a large library of web scraping procedures, to track, scrape, and store information on several hundreds applications on the popular PC video game e-tailer: \href{https://store.steampowered.com/}{Steam}. This was largely achieved by using Steam's Web API, but also by scraping data from webpages, dashboards, and portals. The data retrieved by said procedures would be stored in a database, accessible via a web API. Most of the endpoints within this API perform various complex manipulations and aggregates to return a representation of the data that is easier to handle for users. This interest soon stemmed into my professional life, when I was asked to implement this system on a larger scale for a indie video game publisher. Thus increasing the workload and data throughput of the server.

Soon, the complexity of the codebase spiralled out of control. The test suites that were written to check if the procedures were functioning properly, became large and unruly. Frequent and undocumented changes to the Steam Web API, would render some procedures out of action for several days. To deal with this issue, I moved the implementation of some of the test suites to Insomnia (a REST client that allows you to build test suites for web APIs). Whilst having an extensive feature-set for a REST client, Insomnia lacked control-flow constructs for complex request and response handling. Constructs such as conditionals, looping, and error handling, are missing/very hard to implement. Soon after, the tests written in Insomnia were abandoned in favour of refactored versions of the previous tests within the code base itself.

Due to this need of greater functionality, I propose a scripting language purposefully designed as a HTTP client and test suite first.

\begin{center}
\verb|sttp| \textit{(amalgamation of `scripting' and `HTTP')}
\end{center}

\verb|sttp| was made in order to test web APIs that have complex interaction flows, or APIs that are just black boxes. The main features that \verb|sttp| was designed in mind with are:

\begin{enumerate}
    \item \textbf{Builtin HTTP client}. There must be a way to make HTTP requests.
    \item \textbf{Concise, quick and manageable builtin testing}. Tests should be able to be easily implemented and modifiable. There should also be a way of grouping tests for actions that access a similar resource. Just like how REST APIs are designed.
    \item \textbf{JSON values and JSONPath}. All values in \verb|sttp| can be parsed to JSON and back. As most web APIs default to JSON as their interchange format, it made sense to treat all data as JSON. \textbf{JSONPath}, is a syntax for accessing JSON values in the similar vain of XPath for XML\textsuperscript{\cite{goessner_2007}}.
    \item \textbf{Executing HTTP requests concurrently}. Concurrency should be easy and encouraged.
    \item \textbf{Command line usage}. I regularly tinker and test endpoints on the command line. Thus I expect \verb|sttp| should be able to be run from the command line. This means creating a whitespace independent grammar that allows for input to be typed on a single line.
    \item \textbf{Web scraping functionality}. Such as a HTML parser, tree search functions, and filtering.
\end{enumerate}

To achieve this, I decided to write an interpreter using Go\textsuperscript{\cite{the_go_programming_language}} and the participle parser generator\textsuperscript{\cite{thomas_2021}}. I chose Go as its accompanying toolset allows for quick testing and benchmarking. I knew this would be useful when developing the language and benchmarking the concurrency constructs within the language. This native tooling also allows for rapid development and less external dependencies. At the beginning of the project I was comfortable at writing code in Go, as I had used it for numerous other projects in the past.

I chose the participle parser generator, as it was (and still is) being actively developed, and had a plethora of examples available. It also has an interesting way of defining the accepted grammar for the generated parser. Encoding EBNF within the AST type declarations, the instantiated versions of which will be returned by the generated parser (explained further in PLACEHOLDER). However, the generated parsers are recursive descent parsers. This meant I had to design my language without any left-recursion. Thankfully, the iteration operator in participle's EBNF notation, solved some of the issues, such as left-associative operators.

\section{The Future}

As explained in the \hyperref[chap:motivations]{motivations introduction}, much of my professional life and pastimes involve creating and testing web APIs. Therefore, \verb|sttp| is something that I would hope to use in both domains. I plan on continuing development on \verb|sttp| in the background to add newer features that will solve issues that occur frequently in my work life. Go is also rising in popularity within the web API space, and now that I am fairly fluent in it, I hope to use it within the workplace soon.

As I enjoyed learning the theory behind programming language design and engineering as much as I enjoyed creating \verb|sttp|. I hope I can make better use of this knowledge in the appropriate field of work. I have found the material covered within \textit{CS3480: Software Language Engineering}, quite eye-opening as to the number of different Domain Specific Languages (DSL), in use and in development. There is a DSL for everything from CAD 3D modelling to programming robots\textsuperscript{\cite{nordmann_hochgeschwender_wrede_2014}}. A job within this area could have work that I find rewarding and interesting.

\chapter{Development}
\label{chap:development}

Before development began I wrote a few test programs to get back up to speed with programming in Go, as well as familiarising myself with participle.

\section{Four-function calculator and participle}
\label{sec:four-function-calc}

When declaring a \verb|struct| in Go, the programmer can encode custom annotations (tags) for each field within the structure. These can be accessed using the native \verb|reflect| package. Usually, these are used for denoting how a value will be encoded by an encoder, but can be anything. In participle, you first define the AST nodes, in the form of structures, that will be produced by the generated parser. Then embed the grammar of the language within said AST nodes as Go structure tags. This is reminiscent of an attribute grammar, but in reverse. Where you define the attributes, then implement the grammar on top of them. For instance, consider the following Go code for the \verb|Statement| AST node within the four-function calculator.

\begin{figure}[H]
    \begin{minted}{go}
// Statement can either be an expression, variable assignment or variable clear.
// The EBNF for this non-terminal:
//  ( Clear | Assignment | Expression ) ( EOL | ";" | EOF )
type Statement struct {
    // Pointer to Clear statement node. Can be nil of not matched.
    Clear      *Clear      `(   @@`  // "@@" denotes the capture of the type 
                                     // of the field. In this case the Clear
                                     // non-terminal.

    // Pointer to Assignment statement node. Can be nil if not matched.
    Assignment *Assignment `  | @@`

    // Pointer to Expression statement node. Can be nil if not matched.
    // EOL and EOF are passed into the parser from lexer.
    // Each statement can be finished by either an EOL, semicolon or EOF.
    Expression *Expression `  | @@ ) (EOL | ";" | EOF)`
}

// Each node implements the same Eval function signature.
// This means each node implements an interface which defines
// such a signature.
// The Memory type is a map containing the current values of each defined
// variable and is passed to each Eval function.
func (s *Statement) Eval(ctx Memory) (float64, *Memory) {
    // Nil switch as we have three alternates.
    switch {
    case s.Clear != nil:
        s.Clear.Eval(ctx)
        return 0, &ctx
    case s.Assignment != nil:
        s.Assignment.Eval(ctx)
        return 0, &ctx
    }
    return s.Expression.Eval(ctx), &ctx
}
    \end{minted}
    \label{fig:four-func-calc-statement-ast-node}
    \cprotect\caption{The \verb|Statement| AST node/non-terminal from the four-function calculator test program, along with its \verb|Eval| instance method.}
\end{figure}

When defining an AST node within participle it is treated as a non-terminal within the grammar. Each field is a terminal/non-terminal that is part of the EBNF for the parent non-terminal. The EBNF for the \verb|Statement| non-terminal above would be:

\begin{minted}{ebnf}
Statement = ( Clear | Assignment | Expression ) ( EOL | ";" | EOF );
\end{minted}

\verb|Clear|, \verb|Assignment|, and \verb|Expression| are all other AST nodes/non-terminals that are defined with their own structures within the code base. Whereas, \verb|EOL|, \verb|";"|, and \verb|EOF| are tokens passed from the participle lexer. This EBNF is taken and split across all the fields within the \verb|Statement| structure by the programmer. The types of the field within AST nodes/non-terminals will either be:

\begin{itemize}
    \item Pointers to other AST nodes/non-terminals. These can also be contained within an array when used in conjunction with an EBNF repetition operator. These can be \verb|nil| if the non-terminal is not matched.
    \item Any other type of value, which can be set by in-built tokens or custom tokens. For instance the in-built token \verb|Number| will match any integer, or floating point number and returns a pointer to a \verb|float64|.
\end{itemize}

Once the parser is generated, and an input within the language is parsed, an AST will be produced that will contain the user declared AST nodes as explained above. This means that any AST node can be given any user defined instance method (using Go's receiver syntax). For instance, in the \hyperref[fig:four-func-calc-statement-ast-node]{example above} I also defined an \verb|Eval| instance method which will recursively evaluate either the \verb|Clear| node, \verb|Assignment| node, or the \verb|Expression| node. The result of which will be returned by the \verb|Statement| node. This allows the programmer to encode the semantics of every non-terminal, and hence every AST node, for their grammar. To evaluate the AST then, you would just call the \verb|Eval| instance method on the root of the AST. This would traverse and evaluate each node within it.

To encapsulate the behavior of multiple AST nodes, the programmer could define an \verb|interface| which implements the necessary instance methods for a set of AST node types. For instance, the following interface could be declared to define all AST nodes that can be evaluated.

\begin{minted}{go}
// Evaluatable defines all the AST nodes within the four-function 
// calculator that can be evaluated.
type Evaluatable interface {
    Eval(ctx Memory) float64
}
\end{minted}

This allows the programmer to enforce some sort of ambiguity within their AST, which makes the evaluation of things such as expression trees, much easier. The four-function calculator's AST nodes also implement Go's \verb|Stringer| interface which allows for the code to be pretty-printed.

The four-function calculator supports expression evaluation, variable assignment and deletion, and also has an interactive Repeat-Eval-Print Loop (REPL) mode. Its grammar, semantics and pretty-printer, are all defined within the \verb|test_programs/four_func_calc/calc.go| file.

\begin{figure}[H]
    \begin{minted}{ebnf}
(*              Tokens               *)
(* Number     = `([0-9]*[.])?[0-9]+` *)
(* Ident      = `[a-zA-Z_]\w*`       *)
(* EOL        = `[\n\r]+`            *)
(* Punct      = `[()*+-/=;]`         *)
(* Lowercase tokens are matched but  *)
(* are not passed to the parser      *)
(* whitespace = `\s*`                *)

(* Grammar *)
Script     = { Statement } ;
Statement  = ( Clear | Assignment | Expression ) (EOL | ";" | EOF) ;
Assignment = "let" Ident "=" Expression ;
Clear      = "clear" Ident ;
Expression = Term { OpTerm } ;
OpTerm     = ("+" | "-") Term ;
Term       = Factor { Product } ;
Product    = ("*" | "/") Factor ;
Factor     = Number | Ident | "(" Expression ")" ;
    \end{minted}
    \cprotect\caption{The tokens and grammar for the four-function calculator unwrapped from the Go code.}
\end{figure}

More information on how to use the four-function calculator can be found in the \verb|README|.

\section{Regex minimiser}

After writing the four-function calculator implementation I decided to translate some of the algorithms and methods used within lexical analysis described by the \textit{CS3470: Compilers And Code Generation} course. I did this mainly to supplement my learning and to understand how the algorithms worked. The implementation consists of a participle attribute grammar which accepts a language of simple regular expressions. The accepted notation includes: concatenation, alternation, grouping, and Kleene Closure and is described by the following EBNF grammar:

\begin{figure}[H]
    \begin{minted}{ebnf}
(*         Tokens        *)
(* Punct      = `[()*|]` *)
(* Char       = `[a-z]`  *)
(* whitespace = `\s*`    *)

(* Grammar *)
Base = Char | "(" Regex ")" ;
Factor = Base [ "*" ] ;
Term = { Factor } - ;
Regex = Term [ "|" Regex ] ;
    \end{minted}
    \cprotect\caption{The tokens and grammar for the regular expression parser test program unwrapped from the Go code.}
\end{figure}

The implementation minifies an input regular expression in three phases.

\subsection{Thompson's Construction}
\cprotect\textit{Source located in: \verb|test_programs/thompsons/thompsons.go|}

Thompson's construction is carried out in a single traversal of the produced AST. This is done by having each AST node implement the following interface:

\begin{minted}{go}
type Thompsons interface {
    Thompson(graph *Graph) (start State, end State)
}
\end{minted}

The \verb|Thompsons| instance method takes a pointer to a \verb|Graph| type, which is represented as an adjacency list internally, and returns a start node and an end node. This is because each one of Thompson's constructions modifies the NFA and can also introduce a new start point and end point to the NFA. For instance, in the case of alternation (\verb+"|"+) the new start and end point will be set to the created nodes that join to the existing nodes using the epsilon transition.

\begin{figure}[H]
    \begin{minted}{go}
// Thompson construction for a Regex symbol.
func (r *Regex) Thompson(graph *Graph) (start State, end State) {
    start, end = r.Term.Thompson(graph)
    if r.Regex != nil {
        // If the Regex symbol exists then we construct the union
        // between the Term and the Regex symbol.
        start2, end2 := r.Regex.Thompson(graph)
        start, end = graph.Union(start, end, start2, end2)
    }
    return start, end
}
    \end{minted}
    \cprotect\caption{An example taken from \verb|test_programs/thompsons/thompsons.go| showing the \verb|Thompson| instance method for the \verb|Regex| AST node/non-terminal.}
\end{figure}

In the example shown above, the \verb|Term| node will be executed first. This will produce a sub-NFA that has a start, and an end point. If the \verb|Regex| field is not nil, this means that there is an alternation (\verb+"|"+) within the regular expression. This \verb|Regex| AST node/non-terminal will first be evaluated, and the alternation/union of the two will be constructed in the \verb|Graph| (using the \verb|Union| instance method). Due to \verb|Regex| being the start non-terminal of the grammar, it is possible that this method could return the finished start and end points of the fully constructed NFA.

\subsection{Subset Construction}
\cprotect\textit{Source located in: \verb|test_programs/thompsons/subset.go|}

After the NFA has been produced, the \verb|Graph| instance mentioned above is then passed to the subset construction algorithm to construct a (non-minimal) DFA. It is important to note that the \verb|AdjacencyList| type, that is used within the \verb|Graph| type, has the signature:

\begin{minted}{go}
type AdjacencyList map[StateKey][]Edge

// StateKey represents the key used within AdjacencyLists.
// It wraps both State and StateSet to provide a string key usable in maps.
type StateKey interface {
	// Key generates a key from a State or StateSet.
	Key() string
}
\end{minted}

The \verb|StateKey| interface is used within the \verb|AdjacencyList| type so that both a single state (represented as the \verb|State|), and a set of states (represented as the \verb|StateSet| type) can be easily hashed and used within Go's native \verb|map| type. This is useful when carrying out the subset construction, as it merges multiple states from the NFA into a smaller number of sets of states.

Another type used extensively whilst calculating the subset construction is the \verb|StateSetExistence| type. \verb|StateSetExistence| denotes a unique set of states, and is used when calculating the possible inputs accepted by the regular expression as well as the epsilon closure.

\begin{minted}{go}
// StateSetExistence represents a unique set of States.
type StateSetExistence map[StateKeyString]bool

// NOTE: A StateKeyString is the stringified version 
//       of a StateKey, derived using StateKey.Key.
\end{minted}

It makes use of an interesting side effect of Go's \verb|map| type. In that, when accessing a \verb|map| with a key that does not exist within the \verb|map|, the default value of the value type will be returned. The default value for \verb|bool|s is \verb|false|. This creates a succinct way of checking whether an element exists within a set.

I will not be explaining how the \verb|Subset| and \verb|EClosure| instance methods for the \verb|Graph| type work, as they are effectively just implementations of the algorithms showcased in \textit{CS3470}. Their source code can be found in the \verb|test_programs/thompsons/subset.go| file.

\subsection{Dead State Minimisation}

Dead State minimisation requires the DFA to translated into a transition table. To do this, I first created a \verb|TransitionTable| type. This type is essentially a matrix of \verb|StateKeyString| values, so I also created a constructor (\verb|InitTT|) along with it, which takes a \verb|Graph| and returns a newly allocated \verb|TransitionTable|.

\begin{figure}[H]    
    \begin{minted}{go}
// TransitionTable represents the table of all moves from all states with the
// given language, including the dead state. Rows represent the language input
// strings, and Cols represent the possible states from a DFA.
type TransitionTable struct {
    // Table is transition table itself.
    Table           [][]StateKeyString
    // Rows is the number of rows in the TT.
    Rows            int
    // Cols is the number of columns in the TT.
    Cols            int
    // States is an array of all states from the DFA including the DeadState.
    States          []StateKey
    // StateCols is a lookup for where each of the current StateKeyStrings 
    // that span the columns of the TT are stored as column indices.
    StateCols       map[StateKeyString]int
    // Language is the possible inputs for the DFA.
    Language        []string
    // AcceptingStates are all the states that are accepting states. These 
    // are found by doing a lookup within the NFA.
    AcceptingStates StateSetExistence
    // MergedStates is a mapping of StateKeyStrings to StateSetExistences 
    // that indicates which states have been merged during Dead State Minimisation.
    MergedStates    MergedStates
    Verbose         bool
}
    \end{minted}
\end{figure}

\begin{figure}[H]\ContinuedFloat
    \begin{minted}{go}
// InitTT constructs a TransitionTable from the given Graph instance.
func InitTT(graph *Graph, verbose bool) *TransitionTable {
    // Setup the basic metadata for the transition table
    // Truncated to make space...

    // Then fill out the table itself
    for i := range tt.Table {
        tt.Table[i] = make([]StateKeyString, tt.Cols)
        // Set each value accordingly in relation to the DFAs adjacency list.
        for j := range tt.Table[i] {
            if j == 0 {
                // We insert the dead state at col 0 (the dead state)
                tt.Table[i][j] = DeadState
                tt.StateCols[DeadState] = 0
            } else {
                state := tt.States[j]
                tt.StateCols[StateKeyString(state.Key())] = j
                // Then we find out if the state is an accepting state by
                // comparing the key to the NFA
                if graph.CheckIfAccepting(state) {
                    tt.AcceptingStates.Mark(state)
                }

                // Find out which inputs the state can accept
                possibleInputs := make(map[string]*Edge)
                for _, edge := range graph.DFA.Get(state) {
                    possibleInputs[edge.Read] = &edge
                }

                // We set the transition to a dead state by default
                tt.Table[i][j] = DeadState
                for _, edge := range graph.DFA.Get(state) {
                    if edge.Read == tt.Language[i] {
                        tt.Table[i][j] = StateKeyString(edge.Ingoing.Key())
                        break
                    }
                }
            }
        }
    }
    return &tt
}
    \end{minted}
    \cprotect\caption{The \verb|TransitionTable| type and its constructor, that are used within the Dead State minimisation algorithm. This is taken from the \verb|test_programs/thompsons/minimisation.go| file.}
\end{figure}

The \verb|MergedStates| type is important to the execution of the Dead State minimisation algorithm. This is because it includes an instance method that can check if the given merged state differs from the instanced merged state, which is the main condition that must hold for Dead State minimisation to continue. Once this instance method returns \verb|false|, this means that Dead State minimisation is complete and the DFA is minimal.

The source code for the algorithm itself is implemented as an instance method for the \verb|TransitionTable| type, and can be found in the \verb|test_programs/thompsons/minimisation.go| file.

\subsection{Visualisation}

As well as computing the minimal DFA, the regex minimiser also renders the each phase of the execution using the \verb|graphviz| library. This Go version of the graphviz library (\href{https://github.com/goccy/go-graphviz}{go-graphviz}) comes pre-bundled with the C code for graphviz, which will be compiled through Go's compiler using the default C compiler on the target machine. Each time the regex minimiser is called it produces six output files:

\begin{itemize}
    \item \verb|thomspons.png| and \verb|thompsons.dot|: the NFA after carrying out Thompson's construction. \verb|thomspons.dot| is a text file containing code written in graphviz's DSL that can be passed to the graphviz executable to render the NFA. This is the same with the other \verb|*.dot| files below.
    \item \verb|subset.png| and \verb|thompsons.dot|: the non-minimal DFA produced by the subset construction.
    \item \verb|deadstate.png| and \verb|deadstate.dot|: the minimal DFA produced by the Dead State minimisation algorithm.
\end{itemize}

More information on how to run the regex minimiser can be found in the \verb|README|.

\section{The Grammar and the AST}

\begin{center}
    \textbf{Diary Entry}\\[0.5em]
    \textit{``This week I focussed on writing up the grammar for my interpreted programming language. I ended starting the write-up of a grammar and semantics specification as well as the grammar implementation within the participle parser generator. The specification can be found in the reports directory and the go implementation can be found in the src directory. Even though this counts as one of my test programs it will become a part of my finished product, hence why it is located in src."}\\[0.5em]
    \tiny{3:33 pm on October 24, 2021}
\end{center}

After creating the test programs described above, I moved onto starting a formal specification for the programming language. In particular the grammar of the language. The majority of the syntax is based on the syntax of Lua \textsuperscript{\cite{lua_syntax_specification}}. The syntax has been heavily modified in order to make it use tail recursion and some of the other constructs within the language, such as JSONPath and HTTP request methods. It also differs from the Lua syntax specification, as the 5 levels of operator precedence are encoded into the grammar itself. Whereas, Lua's operator precedence is evaluated after parsing. This decision was made after writing a report on \textit{`The use derivation rules, and grammar idioms to capture notions of associativity and precedence in arithmetic expressions'}.

\begin{figure}[H]
    \begin{verbatim}
# Tokens passed to the parser
Number    = `[-+]?(\d*\.)?\d+'
StringLit = `(")([^"\\]*(?:\\.[^"\\]*)*)(")'
Ident     = `[a-zA-Z_]\w*'
Method    = `(GET|HEAD|POST|PUT|DELETE|OPTIONS|PATCH)'
While     = `while\s'
For       = `for\s'
Do        = `\sdo\s'
This      = `this\s'
Break     = `break'
Then      = `\sthen\s'
End       = `end'
Function  = `function\s'
Return    = `return'
Throw     = `throw'
If        = `if\s'
Elif      = `elif\s'
Else      = `else\s'
Catch     = `catch\s'
Test      = `test\s'
In        = `\sin\s'
As        = `\sas\s'
True      = `true'
False     = `false'
Null      = `null'
Batch     = `batch\s'
Try       = `try\s'
Operators = `\|\||&&|<=|>=|!=|==|[-+*/%=!<>]'
Punct     = `[$;,.(){}:]|\[|\]'
# Ignored tokens
comment    = `//.*'
whitespace = `\s+'
    \end{verbatim}
    
    All capitalised symbols are tokens that are passed from the lexical analyser to the parser. Whereas, the uncapitalised symbols are read by the lexical analyser and ignored by the parser.
\end{figure}

\begin{figure}[H]\ContinuedFloat
    \begin{minted}{ebnf}
Program  = Block ;
Block    = { [ Stmt ] ";" } [ RetStmt | ThrwStmt ] ;
Stmt     = Ass
            | FuncCall
            | MethCall
            | Break
            | Test Exp
            | While Exp Do Block End
            | For Ass ";" Exp [ ";" Ass ] Do Block End
            | For Ident [ "," Ident ] In Exp Do Block End
            | Batch This Block End
            | Try This Block Catch As Ident Then End
            | Function JSONPath FuncBody
            | If Exp Then Block { ElifSeg } [ ElseSeg ] End ;

Ass      = JSONPath "=" Exp ;
ElifSeg  = Elif Exp Then Block ;
ElseSeg  = Else Block ;

(* JSON Path *)
JSONPath = Part { "." Part } ;
Part     = Ident { "[" Exp "]" } ;

(* Return and Throw statements can only come at the end of a block *)
RetStmt  = Return [ Exp ] ";" ;
ThrwStmt = Throw [ Exp ] ";" ;

(* Function calls and Method calls must be prefixed by a dollar sign *)
FuncCall = "$" JSONPath Args ;
MethCall = "$" Method Args ;
FuncBody = "(" [Params] ")" Block End ;
Params   = JSONPath { "," JSONPath } ;
Args     = "(" [ExpList] ")" ;
ExpList  = Exp { "," Exp } ;

(* Our "arithmetic expressions" have 5 levels of precedence *)
(* "||": lowest precedence *)
Exp      = Prec5T { Prec5 } ;
Prec5    = Prec5Op Prec5T ;
Prec5Op  = "||" ;

(* "&&": 2nd lowest precedence *)
Prec5T   = Prec4T { Prec4 } ;
Prec4    = Prec4Op Prec4T ;
Prec4Op  = "&&" ;

(* "==" and "!=": 3rd lowest precedence *)
Prec4T   = Prec3T { Prec3 } ;
Prec3    = Prec3Op Prec3T ;
Prec3Op  = "==" | "!=" ;

(* "<", ">", "<=", and ">=": 4th lowest precedence *)
Prec3T   = Prec2T { Prec2 } ;
Prec2    = Prec2Op Prec2T ;
Prec2Op  = "<" | ">" | "<=" | ">=" ;
    \end{minted}
\end{figure}

\begin{figure}[H]\ContinuedFloat
    \begin{minted}{ebnf}
(* "+" and "-": 5th lowest precedence *)
Prec2T   = Prec1T { Prec1 } ;
Prec1    = Prec1Op Prec1T ;
Prec1Op  = "+" | "-" ;

(* "*", "/", and "%": Highest precedence *)
Prec1T   = Factor { Prec0 } ;
Prec0    = Prec0Op Factor ;
Prec0Op  = "*" | "/" | "%" ;

(* The factors are our base values *)
Factor   = Null
            | False
            | True
            | Number
            | StringLit
            | JSONPath
            | JSON
            | FuncCall
            | MethodCall
            | "(" Exp ")" ;

(* JSON literal *)
JSON     = Object | Array ;
Object   = "{" [ Members ] "}" ;
Members  = Pair { "," Pair } ;
Pair     = Exp ":" Exp ;
Array    = "[" [ ExpList ] "]" ;
    \end{minted}
    \cprotect\caption{The Tokens and Grammar of \verb|sttp|}
\end{figure}

After defining the grammar, I started manipulating it into AST nodes so that participle could generate a parser for the language. Below is a summary of all AST nodes and what they denote within the grammar. For a more in-depth description of the semantics of the grammar, see the \hyperref[appendix:sttp-specification]{specification}.

\begin{enumerate}
    \item \verb|JSON|: JSON literal.
    \begin{enumerate}
        \item \verb|Object|: JSON Object within a JSON literal.
        \begin{enumerate}
            \item \verb|Pair|: a key-value pair within an \verb|Object|.
        \item \verb|Array|: JSON Array within a JSON literal.
        \end{enumerate}
    \end{enumerate}
    \item \verb|Factor|: base factor within an expression. Can be one of the following:
    \begin{itemize}
        \item \verb|Null|: token that matches \verb|null|.
        \item \verb|Boolean|: token that matches \verb|true| or \verb|false|, setting a flag.
        \item \verb|Number|: floating point or integer number stored in a \verb|float64|.
        \item \verb|StringLit|: a string literal, stored in a \verb|string|.
        \item \verb|JSONPath|: pointer to a JSONPath AST node. This will get a value pointed to by the JSONPath.
        \item \verb|JSON|: pointer to a JSON AST node.
        \item \verb|FunctionCall|: pointer to a FunctionCall AST node. The return value of the function will be used within the expression.
        \item \verb|MethodCall|: pointer to a MethodCall AST node. The response of the HTTP request will be used within the expression.
        \item \verb|SubExpression|: pointer to an inner Expression AST node. Parenthesised sub-expression.
    \end{itemize}
    \item \verb|PrecNTerm| where \verb|N| is $1-5$: denotes a left hand branch, and right hand branche\textbf{s}, of an expression at the precedence level \verb|N|. Operator precedence from high to low is as follows:
    \begin{enumerate}
        \item \verb|*|, \verb|/|, \verb|%|: Multiplication, division, and modulus.
        \item \verb|+|, \verb|-|: Addition and subtraction.
        \item \verb|<|, \verb|>|, \verb|<=|, \verb|>=|: Less than, greater than, less than or equal to, and greater than or equal to.
        \item \verb|!=|, \verb|==|: Not equal and equal. \textbf{Arithmetic operators and logical operators share expression trees}, this is because \verb|sttp| will employ casting for these operations.
        \item \verb|&&|: Logical AND.
        \item \verb+||+: Logical OR.
    \end{enumerate}
    \item \verb|PrecN| where \verb|N| is $0-5$: denotes the right-hand side of a sub-expression, including the operator for that sub-expression.
    \item \verb|Expression|: represents the AST node at the top level of an expression. Grammatically, this is equal to the \verb|PrecNTerm|s described above.
    \item \verb|FunctionBody|: represents the parameters and body of a function definition. Parameters are comma-separated JSONPath AST nodes. The body of a function is described by a Block AST node.
    \item \verb|MethodCall|: represents a HTTP request using the method after the prefix dollar sign. MethodCalls are syntactically identical to FunctionCalls but the only supported callables are:
    \begin{itemize}
        \item \verb|GET|: Does not take a request body.
        \item \verb|HEAD|: Does not take a request body.
        \item \verb|OPTIONS|: Does not take a request body.
        \item \verb|POST|: Takes a request body.
        \item \verb|PUT|: Takes a request body.
        \item \verb|DELETE|: Takes a request body.
        \item \verb|PATCH|: Takes a request body.
    \end{itemize}
    \item \verb|FunctionCall|: any JSONPath can be `called'. Arguments are pointer to Expression AST nodes.
    \item \verb|ReturnStatement|: denotes a \verb|return| statement that can only be used at the end of a Block. The return value is optional, if not given, \verb|null| is returned.
    \item \verb|ThrowStatement|: denotes a \verb|throw| statement that can only be used at the end of a Block. The value being thrown is optional, if not given, \verb|null| is returned.
    \item \verb|TestStatement|: used to test an expression for a truthy value. Primarily, this is used within a directory of test scripts, but can also be used within individual scripts.
    \item \verb|JSONPath|: used to get the value given at the given JSONPath. It is constructed from Parts separated by `\verb|.|'.
    \begin{enumerate}
        \item \verb|Part|: represents a property within a JSONPath, that can be followed by any number of indices.
        \begin{enumerate}
            \item \verb|Index|: can either be square brackets surrounding an Expression, evaluated to a String, or a Number. Can also be a filter Block, which is a Block AST node executed on each node within the current level of the value that the JSONPath is accessing. If the Block returns a truthy value for that node, then that node will be added to the result Array.
        \end{enumerate}
    \end{enumerate}
    \item \verb|Statement|: a statement exists within a Block and can be one of the following:
    \begin{enumerate}
        \item \verb|Assignment|: setting the JSONPath on the LHS to the Expression on the RHS.
        \item \verb|FunctionCall|: the return value from a function call.
        \item \verb|MethodCall|: the response from HTTP request.
        \item \verb|Break|: the break keyword. Breaks out of any loop.
        \item \verb|TestStatement|: a test statement.
        \item \verb|While|: a while loop. Checks a condition and evaluates a Block.
        \item \verb|For|: an `old style' for loop. Define an iterator value, a predicate, and an assignment to carry out at the end of each iteration.
        \item \verb|ForEach|: a `new style' for-each loop. Two iterator values can be defined for key-value iteration.
        \item \verb|Batch|: executes all MethodCalls within it concurrently.
        \item \verb|TryCatch|: try-catch-as structure. The error caught in \verb|try| will be stored in an identifier and not a JSONPath.
        \item \verb|FunctionDefinition|: define a function that will be stored in the given JSONPath with the given FunctionBody.
        \item \verb|IfElifElse|: a conventional if-elif-else statement for control flow.
    \end{enumerate}
    \item \verb|Block|: a list (or `block') or Statements, each of which must be terminated with a semicolon. A ReturnStatement or ThrowStatement can be added at the end of a Block.
    \item \verb|Program|: the start non-terminal of the grammar. Matches a Block.
\end{enumerate}

The implementation of the AST within Go will be skipped as this has been discussed extensively when discussing the \hyperref[sec:four-function-calc]{four-function calculator} test program. The type definitions for each AST node within \verb|sttp| can be found within \verb|src/parser/ast.go|. However, an interesting feature to note is that any AST node type definition can be given a \verb|Pos lexer.Position| field. This will automatically be populated by the position (filename, line, column) of that non-terminal within the input.

I found that defining the behaviour of each AST node sequentially, allowed me to create examples for that AST node easily. This allowed me to thoroughly test the behaviour of each AST node.

\subsection{Pretty-printer}

\begin{center}
    \textbf{Git commit}
    \begin{minted}{markdown}
Language spec: String() referrers + grammar tweaks
- Had to tweak grammar some more as well as lexer regex (21/10/2021 - 22:23:07)
- Modified grammar rules in spec as well (21/10/2021 - 22:23:30)
- One tweak was adding a 'set' string before assignments so that the grammar
  can be parsed with a lookahead of 2 (21/10/2021 - 22:25:17)
- Wrote a prelimenary example to do a little test (21/10/2021 - 22:25:40)
- Added a test so that I could visualise parse (21/10/2021 - 22:26:00)
- Added string.go file which has referrers for symbol structs to enable the
  printing of the structure of a program (21/10/2021 - 22:26:38)
    \end{minted}
    \vspace{-1em}
    \tiny{October 21, 2021}
\end{center}

Before starting on the implementation of the interpreter itself, I first created a pretty-printer for the AST. This is done in a similar way as to the one used in the \hyperref[sec:four-function-calc]{four-function calculator}. However, rather than implementing Go's native \verb|Stringer| interface, I implement my own interface:

\begin{minted}{go}
type indentString interface {
    String(indent int) string
}
\end{minted}

The \verb|String| instance method takes the level of indentation to apply to the node. This is so statements such as \verb|IfElifElse|, \verb|While|, \verb|For|, etc. can be indented properly. Then when stringing an inner \verb|Block|, \verb|indent| can be incremented to visually indent that block, such as the following for the \verb|TryCatch| statement.

\begin{minted}{go}
func (tc *TryCatch) String(indent int) string {
    // tabs is a function which returns the given number as "\t" chars
    return fmt.Sprintf(
        "%stry this\n%s%scatch as %s then\n%s%send",
        tabs(indent),
        tc.Try.String(indent + 1),
        tabs(indent),
        *tc.CatchAs,
        tc.Caught.String(indent + 1),
        tabs(indent),
    )
}
\end{minted}

These \verb|String| instance methods can be found in the \verb|src/parser/string.go| file. The pretty-printer allowed me to debug some of the early mistakes within the grammar and AST nodes. This test case is \verb|TestParse| and is located within \verb|src/main_test.go|.

\subsection{A problem with the grammar}

\begin{center}
    \textbf{Diary Entry}\\[0.5em]
    \cprotect\textit{``Just found a mistake within the sttp grammar. The non-terminal for function calls is: \verb|JSONPath "(" (@@ ( "," @@ )*)? ")"|, and the non-terminal for variable access is: \verb|JSONPath|. Because both function calls and variable access can both derive a Factor within an expression this leads to function calls being misidentified as function calls. To fix this I added a ``\verb|$|" token as syntactic sugar before the JSONPath for function calls so that there is no clash between the two non-terminals."}\\[0.5em]
    \tiny{5:05 pm on December 8, 2021}
\end{center}

As described by the diary entry above. There was a mistake within the grammar for the non-terminals: \verb|FunctionCall| and \verb|JSONPath|. This mistake lead to a $FIRST$ set clash, which lead to FunctionCalls being parsed as JSONPaths within Expressions, as both can derive Factor. To solve this, I added `\verb|$|' as a suffix for FunctionCalls (and MethodCalls for consistency), which solves the $FIRST$ set clash.

Solving this also allowed me to change the grammar of assignment statements. The original grammar for \verb|Assignment| was:

\begin{minted}{ebnf}
Assignment = "set" JSONPath "=" Expression ;
\end{minted}

\section{Data-structures}

\begin{center}
    \textbf{Git commit}
    \begin{minted}{markdown}
Language: eval package + evaluation datastructures
- Added eval package which will include the datastructures necessary for
  evaluation of ASTs (08/11/2021 - 18:41:35)
- Added error file within eval which stores format string constants used
  in error reporting (08/11/2021 - 18:42:04)
- Added the heap datastructure which will store the variables within a
  virtual machine (08/11/2021 - 18:42:39)
- Added the VM interface as well as an implementation of it which will
  be passed to each node in the AST in their Eval referrers (08/11/2021 - 18:43:32)
- Added the beginning of some tests in the eval package (08/11/2021 - 18:44:05)
    \end{minted}
    \vspace{-1em}
    \tiny{November 8, 2021}
\end{center}

After implementing the pretty-printer, I moved onto defining the main data-structures (besides the AST) for the \verb|sttp| interpreter.

\subsection{Heap}
\label{sec:data-structures-heap}

I first defined a \verb|Heap| structure that would form the basis of variable storage within the interpreter. This was originally defined as a mapping of variable names to a linked list of symbols sorted in scope ascending order. An instance of this \verb|Heap| would sit within the data-structure that manages the state of the VM.

\begin{minted}{go}
type Heap map[string][]*Symbol
\end{minted}

However, this was an over-complication of what should be a simple data-structure. It was later refactored to be a mapping of variable names to current values, then a new instance of a \verb|Heap| would be initialised for every stack frame. Global variables, such as \verb|FunctionDefinition|s would then be copied/referenced to within this new \verb|Heap|. Once the stack frame `returns', the \verb|Heap| can be automatically deallocated by Go's garbage collector. Internally, this is represented by the following Go types.

\begin{minted}{go}
// Heap stores variable values on a stack frame.
type Heap map[string]*Value

// Value represents a value stored on the Heap. It can take any value that is
// capable of being marshalled to JSON. The Global flag indicates whether to
// reference the Value on all frames that are added to the stack. The ReadOnly
// flag indicates whether or not the value is mutable.
type Value struct {
    Value    interface{} `json:"value"`
    Type     Type        `json:"type"`
    Global   bool        `json:"global"`
    ReadOnly bool        `json:"readOnly"`
}

// Type denotes the type of a value. It is defined by a set of constants.
type Type int

const (
    // NoType is used for logic within the Heap referrers.
    NoType Type = iota
    // Object is a standard JSON object.
    Object
    // Array is a standard JSON array.
    Array
    String
    // Number can be either floating point or an integer.
    Number
    Boolean
    // Null is a falsy value that indicates nothing.
    Null
    // Function cannot be stored in a variable per-say but is put on the heap
    // as a symbol. A symbol which has a Function type has a value which points
    // to a FunctionBody struct.
    Function
)
\end{minted}

\verb|Heap| implements the following interface so that it can be read from and written to.

\begin{minted}{go}
type Heap interface {
    // Exists will check whether the variable of the given name is on the heap.
    Exists(name string) bool
    // Delete will delete the symbol of the given name in the given scope.
    // If scope is negative then the most recent symbol will be deleted.
    Delete(name string)
    // Assign will create a new entry in the heap if the variable does not exist yet.
    // Otherwise, will assign the new value and type to the existing symbol.
    // The type of the symbol will be decided by Type.Get
    Assign(name string, value interface{}, global bool, ro bool) (err error)
    // Get will retrieve the symbol of the given name in the given scope.
    // Nil will be returned if the variable of the given name does not exist.
    Get(name string) *Value
}
\end{minted}

The source code for \verb|Heap|, \verb|Value|, and \verb|Type|, as well as any instance methods for these types, can be found in \verb|src/data/heap.go|.

\subsection{Frames and the CallStack}

\begin{center}
    \textbf{Git commit}
    \begin{minted}{markdown}
Language: call stack + VM + more tests
- Added test case for delete (not yet filled) (09/11/2021 - 00:22:09)
- Added Function type (09/11/2021 - 00:22:40)
- Fixed problems in New and Assign referrers for Heap (09/11/2021 - 00:23:16)
- Moved the interfaces file to the parser package to stop circular imports (09/11/2021 - 00:23:36)
- Added the CallStack interface and implementation (09/11/2021 - 00:24:49)
- Added runtime errors file (09/11/2021 - 00:25:18)
- Moved errors to package (09/11/2021 - 00:25:25)
- Added a custom error interface (09/11/2021 - 00:33:15)
    \end{minted}
    \vspace{-1em}
    \tiny{November 10, 2021}
\end{center}

As hinted to \hyperref[sec:data-structures-heap]{above}, the design of the \verb|Frame| type changed when the \verb|Heap| type was changed. Initially, it only included a pointer to the \verb|FunctionCall| that called the function, a pointer to the \verb|FunctionDefinition| that is currently being executed, and a return value. However, as memory management now depends on the frames pushed to the call stack, each \verb|Frame| now includes a pointer to a \verb|Heap|. As for instance methods, the \verb|Frame| type has a getter for each field within it. This is so that the \verb|Frame| type can be used in functions/function signatures by interface only. This is vital, as the \verb|Frame| type is defined in the \verb|main| package, making it inaccessible directly from packages that reside lower than it. For this reason, the \verb|src/parser/interfaces.go| file defines a few interfaces of types defined in the \verb|main| package, including an interface for \verb|Frame|.

The \verb|CallStack| is implemented as an array of pointers to \verb|Frame|s, with a max size of \verb|MaxStackFrames| (\verb|src/call.go|), it has the following interface.

\begin{minted}{go}
// CallStack is implemented by the call stack that is used within the VM.
type CallStack interface {
    // Call will add a new stack frame to the call stack with the given fields.
    // It will also create a new Heap accordingly with the given computed 
    // arguments as values on the Heap.
    Call(
        caller *FunctionCall,
        current *FunctionDefinition,
        vm VM,
        args ...*data.Value,
    ) error
    // Return will remove the top frame from the call stack and return it.
    Return(vm VM) (err error, frame Frame)
    // Current will return the top of the call stack but not return it.
    Current() Frame
    fmt.Stringer
}
\end{minted}

The \verb|Call| instance method will first create a new \verb|Heap| and \verb|Frame| (using the \verb|Heap|) and push it to the top of the call stack. If the number of arguments given is greater than the number of parameters of the function, then a \verb|MoreArgsThanParams| error is returned. Otherwise, all \verb|Value|s from the below frame with their \verb|Global| flag set will be copied over by reference to the new \verb|Heap| located on the current frame. Then we create a variable: \verb|self|, that contains the value pointed to by the \textbf{root property} (the first property of a JSONPath, e.g. \verb|json| in \verb|json.hello.world[0]|) of the JSONPath of the \verb|FunctionDefinition| currently being called.

Then the interpreter will iterate over each defined parameter of the function that is being pushed to the stack. If an argument is given for this parameter (its index within parameters is less than the arguments available), the value of the argument will be set to the value pointed to by the JSONPath of the current parameter. Otherwise, the value: \verb|null| will be used. If the root property of the current parameter's JSONPath already exists on the stack, then the value of that parameter will be set to the value resulted by setting the argument fetched earlier to the value pointed to by the JSONPath of the current parameter within this existing value. This allows programmers using \verb|sttp| to `build' input values using JSONPath. For instance:

\begin{verbatim}
function hello(input.name, input.world, input.exclamation)
    foo(input.name);
    return "Hello %% %%" % [input.name, input.world, input.exclamation]
end;
\end{verbatim}

This is explained more within the \hyperref[sec:function-heap]{specification}. The code which achieves this parameter setting is defined within the \verb|src/call.go| file.

\inputminted[firstline=88, lastline=130, autogobble, breaklines]{go}{../../src/call.go}

The \verb|Return| instance method for \verb|CallStack| will first pop the topmost \verb|Frame| from the \verb|CallStack|.

\subsection{VM}

\section{Casting}

\section{Operators}

\section{Evaluating AST nodes}

\subsection{JSONPath and Assignment}

\subsubsection{JSONPath}

\subsubsection{Assignment}

\subsection{Expressions}

\subsection{If-Elif-Else}

\subsection{Iteration}

\subsection{Functions}

\subsection{HTTP Methods}

\subsubsection{Response Parsing}

\cprotect\subsection{Test suites and the \verb|test| statement}

\cprotect\subsection{Try-Catch and \verb|throw|}

\cprotect\subsection{The \verb|batch| statement}

\subsubsection{Updating the echo-chamber test web API}

\subsubsection{Performance}

\section{Builtins}

\chapter{Evaluation}
\label{chap:evaluation}

\chapter{Discussion}
\label{chap:discussion}

\chapter{Professional Issues}
\label{chap:professional-issues}

%%%%%%%%%%%%%%%%%%%%%%
%%% sttp Specification

\appendix

\cprotect\chapter{\verb|sttp| Specification}
\label{appendix:sttp-specification}

\verb|sttp| (amalgamation of \textit{scripting} and \textit{HTTP}) is a dynamically typed, interpreted, scripting language written in Go using the participle parser generator by Alec Thomas\textsuperscript{\cite{thomas_2021}}. Below is the formal grammar definition of the language:

\import{../specification_for_language}{specification_for_language_body.tex}

%%%% ADD YOUR BIBLIOGRAPHY HERE
\newpage
\label{endpage}

\printbibliography

\end{document}

\end{article}
